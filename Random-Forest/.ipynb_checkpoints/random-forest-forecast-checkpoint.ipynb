{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Forecasting of Volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we complete the tree-based forecasting models for the volatility of the stock data, by implementing a random forest predictor on the time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Preprocessing\n",
    "\n",
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np \n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from seaborn import set_style\n",
    "set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "Loading the data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech = pd.read_csv(\"../data/tech_data.csv\", parse_dates=True)\n",
    "biotech = pd.read_csv(\"../data/biotech_data.csv\", parse_dates=True)\n",
    "healthcare = pd.read_csv(\"../data/healthcare_data.csv\", parse_dates=True)\n",
    "industrial = pd.read_csv(\"../data/industrial_data.csv\", parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a new column `returns` for the daily returns and then `volatility` for the volatility.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the tickers\n",
    "tech_tickers = list(tech.columns[1:])\n",
    "biotech_tickers = list(biotech.columns[1:])\n",
    "healthcare_tickers = list(healthcare.columns[1:])\n",
    "industrial_tickers = list(industrial.columns[1:])\n",
    "\n",
    "for i in range(5):\n",
    "    ## tech stocks\n",
    "    tech[f\"{tech_tickers[i]}_returns\"] = np.log(tech[tech_tickers[i]]) - np.log(tech[tech_tickers[i]].shift(-1))\n",
    "    tech[f\"{tech_tickers[i]}_volatility\"] = tech[f\"{tech_tickers[i]}_returns\"].rolling(30).std()\n",
    "\n",
    "    ## biotech stocks\n",
    "    biotech[f\"{biotech_tickers[i]}_returns\"] = np.log(biotech[biotech_tickers[i]]) - np.log(biotech[biotech_tickers[i]].shift(-1))\n",
    "    biotech[f\"{biotech_tickers[i]}_volatility\"] = biotech[f\"{biotech_tickers[i]}_returns\"].rolling(30).std()\n",
    "\n",
    "    ## healthcare stocks\n",
    "    healthcare[f\"{healthcare_tickers[i]}_returns\"] = np.log(healthcare[healthcare_tickers[i]]) - np.log(healthcare[healthcare_tickers[i]].shift(-1))\n",
    "    healthcare[f\"{healthcare_tickers[i]}_volatility\"] = healthcare[f\"{healthcare_tickers[i]}_returns\"].rolling(30).std()\n",
    "\n",
    "    ## industrial stocks\n",
    "    industrial[f\"{industrial_tickers[i]}_returns\"] = np.log(industrial[industrial_tickers[i]]) - np.log(industrial[industrial_tickers[i]].shift(-1))\n",
    "    industrial[f\"{industrial_tickers[i]}_volatility\"] = industrial[f\"{industrial_tickers[i]}_returns\"].rolling(30).std()\n",
    "\n",
    "\n",
    "## remove missing values\n",
    "tech.dropna(inplace=True)\n",
    "biotech.dropna(inplace=True)\n",
    "healthcare.dropna(inplace=True)\n",
    "industrial.dropna(inplace=True)\n",
    "\n",
    "## reset the index\n",
    "tech.reset_index(inplace=True, drop=True)\n",
    "biotech.reset_index(inplace=True, drop=True)\n",
    "healthcare.reset_index(inplace=True, drop=True)\n",
    "industrial.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split\n",
    "\n",
    "Here we make the train-test split for the data. We will hold back approximately 20% of the data for the test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitting_index = int(len(tech.index)*0.8)\n",
    "\n",
    "tech_train, tech_test = tech[:splitting_index].copy(), tech[splitting_index:].copy()\n",
    "biotech_train, biotech_test = biotech[:splitting_index].copy(), biotech[splitting_index:].copy()\n",
    "healthcare_train, healthcare_test = healthcare[:splitting_index].copy(), healthcare[splitting_index:].copy()\n",
    "industrial_train, industrial_test = industrial[:splitting_index].copy(), industrial[splitting_index:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Random Forest Fitting\n",
    "\n",
    "We will fit a random forest regressor to the returns. To determine the size of the rolling window, we cross validate with different window sizes and see which performs the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [5,10,30,60,90]\n",
    "\n",
    "horizon = len(tech_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform a $3$-fold cross validation to determine which window size is best on the training data. Each will forecast $649$ days, which is the prediction horizon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the $3$-fold object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = TimeSeriesSplit(n_splits=3,\n",
    "                        test_size=horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the cross validation for the tech stocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_results = pd.DataFrame(index=window_sizes, columns=tech_tickers)\n",
    "\n",
    "for stock in tech_tickers:\n",
    "\n",
    "    ## make empty array for the mses\n",
    "    mses = {k:[0]*5 for k in window_sizes}\n",
    "    ## this keeps track of which split we are on\n",
    "    i = 0\n",
    "    for train_index, test_index in kfold.split(tech_train[f'{stock}_returns']):\n",
    "            \n",
    "        train = tech_train.loc[train_index, f'{stock}_returns']\n",
    "        holdout = tech_train.loc[test_index, f'{stock}_returns']\n",
    "\n",
    "        for window in window_sizes:\n",
    "            X_train = np.concatenate([train.shift(t).values.reshape(-1,1) for t in range(1,window+1)],\n",
    "                                     axis=1)[window:]\n",
    "            y_train = train.values[window:]\n",
    "\n",
    "            rf = RandomForestRegressor(max_depth=5)\n",
    "            rf.fit(X_train, y_train)\n",
    "\n",
    "            X_holdout = np.concatenate([holdout.shift(t).values.reshape(-1,1) for t in range(1,window+1)],\n",
    "                                     axis=1)[window:]\n",
    "\n",
    "            pred = rf.predict(X_holdout)\n",
    "\n",
    "            mses[window][i] = mean_squared_error(tech_train.loc[test_index, f'{stock}_volatility'].values[window:], \n",
    "                                                 pred)\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "\n",
    "    for window in mses.keys():\n",
    "        tech_results.loc[window, stock] = np.mean(mses[window])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NVDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.00042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AAPL      AMZN     GOOGL      MSFT      NVDA\n",
       "5   0.000219  0.000243  0.000166  0.000172   0.00042\n",
       "10  0.000214  0.000242  0.000166  0.000173  0.000435\n",
       "30  0.000214  0.000233  0.000169  0.000173  0.000441\n",
       "60  0.000218  0.000247  0.000172  0.000179  0.000444\n",
       "90  0.000215   0.00025  0.000165  0.000183  0.000456"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL has the best window size of 10\n",
      "AMZN has the best window size of 30\n",
      "GOOGL has the best window size of 90\n",
      "MSFT has the best window size of 5\n",
      "NVDA has the best window size of 5\n"
     ]
    }
   ],
   "source": [
    "for tick in tech_results.columns:\n",
    "    print(f\"{tick} has the best window size of\", tech_results.index[np.argmin(tech_results[f'{tick}'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform the same analysis for all of the industries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JNJ has the best window size of 5 with mses of 0\n",
      "LLY has the best window size of 10 with mses of 1\n",
      "MRK has the best window size of 5 with mses of 0\n",
      "NVO has the best window size of 90 with mses of 4\n",
      "RHHBY has the best window size of 30 with mses of 2\n"
     ]
    }
   ],
   "source": [
    "## BIOTECH STOCKS\n",
    "biotech_results = pd.DataFrame(index=window_sizes, columns=biotech_tickers)\n",
    "\n",
    "for stock in biotech_tickers:\n",
    "\n",
    "    ## make empty array for the mses\n",
    "    mses = {k:[0]*5 for k in window_sizes}\n",
    "    ## this keeps track of which split we are on\n",
    "    i = 0\n",
    "    for train_index, test_index in kfold.split(biotech_train[f'{stock}_returns']):\n",
    "            \n",
    "        train = biotech_train.loc[train_index, f'{stock}_returns']\n",
    "        holdout = biotech_train.loc[test_index, f'{stock}_returns']\n",
    "\n",
    "        for window in window_sizes:\n",
    "            X_train = np.concatenate([train.shift(t).values.reshape(-1,1) for t in range(1,window+1)],\n",
    "                                     axis=1)[window:]\n",
    "            y_train = train.values[window:]\n",
    "\n",
    "            rf = RandomForestRegressor(max_depth=5)\n",
    "            rf.fit(X_train, y_train)\n",
    "\n",
    "            X_holdout = np.concatenate([holdout.shift(t).values.reshape(-1,1) for t in range(1,window+1)],\n",
    "                                     axis=1)[window:]\n",
    "\n",
    "            pred = rf.predict(X_holdout)\n",
    "\n",
    "            mses[window][i] = mean_squared_error(biotech_train.loc[test_index, f'{stock}_volatility'].values[window:], \n",
    "                                                 pred)\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "\n",
    "    for window in mses.keys():\n",
    "        biotech_results.loc[window, stock] = np.mean(mses[window])\n",
    "\n",
    "\n",
    "for tick in biotech_results.columns:\n",
    "    print(f\"{tick} has the best window size of\", biotech_results.index[np.argmin(biotech_results[f'{tick}'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMGN has the best window size of 10\n",
      "CVS has the best window size of 30\n",
      "ELV has the best window size of 10\n",
      "PFE has the best window size of 5\n",
      "UNH has the best window size of 5\n"
     ]
    }
   ],
   "source": [
    "## HEALTHCARE STOCKS\n",
    "healthcare_results = pd.DataFrame(index=window_sizes, columns=healthcare_tickers)\n",
    "\n",
    "for stock in healthcare_tickers:\n",
    "\n",
    "    ## make empty array for the mses\n",
    "    mses = {k:[0]*5 for k in window_sizes}\n",
    "    ## this keeps track of which split we are on\n",
    "    i = 0\n",
    "    for train_index, test_index in kfold.split(healthcare_train[f'{stock}_returns']):\n",
    "            \n",
    "        train = healthcare_train.loc[train_index, f'{stock}_returns']\n",
    "        holdout = healthcare_train.loc[test_index, f'{stock}_returns']\n",
    "\n",
    "        for window in window_sizes:\n",
    "            X_train = np.concatenate([train.shift(t).values.reshape(-1,1) for t in range(1,window+1)],\n",
    "                                     axis=1)[window:]\n",
    "            y_train = train.values[window:]\n",
    "\n",
    "            rf = RandomForestRegressor(max_depth=5)\n",
    "            rf.fit(X_train, y_train)\n",
    "\n",
    "            X_holdout = np.concatenate([holdout.shift(t).values.reshape(-1,1) for t in range(1,window+1)],\n",
    "                                     axis=1)[window:]\n",
    "\n",
    "            pred = rf.predict(X_holdout)\n",
    "\n",
    "            mses[window][i] = mean_squared_error(healthcare_train.loc[test_index, f'{stock}_volatility'].values[window:], \n",
    "                                                 pred)\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "\n",
    "    for window in mses.keys():\n",
    "        healthcare_results.loc[window, stock] = np.mean(mses[window])\n",
    "\n",
    "\n",
    "for tick in healthcare_results.columns:\n",
    "    print(f\"{tick} has the best window size of\", healthcare_results.index[np.argmin(healthcare_results[f'{tick}'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F has the best window size of 10\n",
      "GE has the best window size of 10\n",
      "NEE has the best window size of 5\n",
      "SO has the best window size of 10\n",
      "UNP has the best window size of 30\n"
     ]
    }
   ],
   "source": [
    "## INDUSTRIAL STOCKS\n",
    "industrial_results = pd.DataFrame(index=window_sizes, columns=industrial_tickers)\n",
    "\n",
    "for stock in industrial_tickers:\n",
    "\n",
    "    ## make empty array for the mses\n",
    "    mses = {k:[0]*5 for k in window_sizes}\n",
    "    ## this keeps track of which split we are on\n",
    "    i = 0\n",
    "    for train_index, test_index in kfold.split(industrial_train[f'{stock}_returns']):\n",
    "            \n",
    "        train = industrial_train.loc[train_index, f'{stock}_returns']\n",
    "        holdout = industrial_train.loc[test_index, f'{stock}_returns']\n",
    "\n",
    "        for window in window_sizes:\n",
    "            X_train = np.concatenate([train.shift(t).values.reshape(-1,1) for t in range(1,window+1)],\n",
    "                                     axis=1)[window:]\n",
    "            y_train = train.values[window:]\n",
    "\n",
    "            rf = RandomForestRegressor(max_depth=5)\n",
    "            rf.fit(X_train, y_train)\n",
    "\n",
    "            X_holdout = np.concatenate([holdout.shift(t).values.reshape(-1,1) for t in range(1,window+1)],\n",
    "                                     axis=1)[window:]\n",
    "\n",
    "            pred = rf.predict(X_holdout)\n",
    "\n",
    "            mses[window][i] = mean_squared_error(industrial_train.loc[test_index, f'{stock}_volatility'].values[window:], \n",
    "                                                 pred)\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "\n",
    "    for window in mses.keys():\n",
    "        industrial_results.loc[window, stock] = np.mean(mses[window])\n",
    "\n",
    "\n",
    "for tick in industrial_results.columns:\n",
    "    print(f\"{tick} has the best window size of\", industrial_results.index[np.argmin(industrial_results[f'{tick}'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a summary of the above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******TECH******\n",
      "        AAPL      AMZN     GOOGL      MSFT      NVDA\n",
      "5   0.000219  0.000243  0.000166  0.000172   0.00042\n",
      "10  0.000214  0.000242  0.000166  0.000173  0.000435\n",
      "30  0.000214  0.000233  0.000169  0.000173  0.000441\n",
      "60  0.000218  0.000247  0.000172  0.000179  0.000444\n",
      "90  0.000215   0.00025  0.000165  0.000183  0.000456\n",
      "\n",
      "******BIOTECH******\n",
      "         JNJ       LLY       MRK       NVO     RHHBY\n",
      "5   0.000094  0.000143  0.000111  0.000183  0.000103\n",
      "10  0.000096  0.000136  0.000112  0.000182  0.000103\n",
      "30  0.000098  0.000144  0.000113  0.000182  0.000101\n",
      "60  0.000099  0.000147  0.000118  0.000183  0.000102\n",
      "90  0.000101  0.000145  0.000117  0.000182  0.000103\n",
      "\n",
      "******HEALTHCARE******\n",
      "        AMGN       CVS       ELV       PFE       UNH\n",
      "5   0.000185  0.000152  0.000207  0.000103  0.000179\n",
      "10  0.000183   0.00015  0.000207  0.000104  0.000181\n",
      "30  0.000184  0.000145   0.00021  0.000106  0.000181\n",
      "60  0.000188   0.00015  0.000216  0.000113  0.000189\n",
      "90   0.00019  0.000157  0.000219  0.000114  0.000194\n",
      "\n",
      "******INDUSTRIAL******\n",
      "           F        GE       NEE        SO       UNP\n",
      "5   0.000205  0.000242  0.000111  0.000116  0.000175\n",
      "10  0.000194  0.000231  0.000115   0.00011  0.000164\n",
      "30  0.000195  0.000235  0.000116  0.000113  0.000162\n",
      "60  0.000203  0.000239  0.000116  0.000115  0.000166\n",
      "90  0.000202  0.000248  0.000119  0.000117   0.00017\n"
     ]
    }
   ],
   "source": [
    "print(\"******TECH******\")\n",
    "print(tech_results)\n",
    "print(\"\\n******BIOTECH******\")\n",
    "print(biotech_results)\n",
    "print(\"\\n******HEALTHCARE******\")\n",
    "print(healthcare_results) \n",
    "print(\"\\n******INDUSTRIAL******\")\n",
    "print(industrial_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Random Forest Forecasts on Test Set\n",
    "\n",
    "We now fit the random forest models with moving windows to the test set and evaluate the performance of each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
